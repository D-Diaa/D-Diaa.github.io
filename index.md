---
permalink: /
toc: true

---

I am a Ph.D. student under the supervision of [Florian Kerschbaum](https://cs.uwaterloo.ca/~fkerschb/). I'm also a member of the [Cryptography, Security, and Privacy (CrySP)](https://crysp.uwaterloo.ca) lab at the [University of Waterloo](https://uwaterloo.ca).

I hold a Masters degree in Computer Science from the University of Waterloo and a Bachelor of Science in Computer Engineering and Mathematics from [The American University in Cairo](https://www.aucegypt.edu).

## Research

My research focuses on developing robust watermarking techniques for AI-generated content to combat misinformation and enhance digital trust. I explore adversarial vulnerabilities in current watermarking systems and design robust approaches that withstand targetted scrubbing attempts. I aim to establish watermarking as critical infrastructure for generative AI, ensuring accountability and trustworthiness across various applications.

## Preprints
**A. Diaa**, T. Aremu, and N. Lukas.  
Optimizing Adaptive Attacks against Content Watermarks for Language Models.
[Paper](https://arxiv.org/abs/2410.02440), [Models](https://huggingface.co/collections/DDiaa/watermark-removing-paraphrasers-673e3f01fcceafaa2da7e0cf).

**A. Diaa**, T. Humphries, and F. Kerschbaum.  
FastLloyd: Federated, Accurate, Secure, and Tunable $k$-Means Clustering with Differential Privacy.
[Paper](https://arxiv.org/abs/2405.02437), [Code](https://github.com/D-Diaa/FastLloyd).

RA. Mahdavi, **A. Diaa**, and F. Kerschbaum.  
HE is all you need: Compressing FHE Ciphertexts using Additive HE.
[Paper](https://arxiv.org/abs/2303.09043).

## Publications

N. Lukas, **A. Diaa**, L. Fenaux, and F. Kerschbaum.  
Leveraging Optimization for Adaptive Attacks on Image Watermarks.
International Conference on Learning Representations (ICLR), 2024.
[Paper](https://openreview.net/forum?id=O9PArxKLe1).

**A. Diaa**, L. Fenaux, T. Humphries, M. Dietz, F. Ebrahimianghazani, B. Kacsmar, X. Li, N. Lukas, RA. Mahdavi, S. Oya, E. Amjadian, and F. Kerschbaum.  
Fast and Private Inference of Deep Neural Networks by Co-designing Activation Functions.
Usenix Security Symposium, 2024.
[Paper](https://www.usenix.org/system/files/sec24summer-prepub-373-diaa.pdf), [Code](https://github.com/LucasFenaux/PILLAR-ESPN).

S. Sav, **A. Diaa**, A. Pyrgelis, J. Boussat, and J. Hubaux.  
Privacy-Preserving Federated Recurrent Neural Networks.
Proceedings on Privacy Enhancing Technologies (PoPETs), 2023.
[Paper](https://petsymposium.org/popets/2023/popets-2023-0122.pdf)

## Resume

<div style="border: 1px solid #ccc; padding: 10px; margin: 20px 0;">
    <iframe src="{{ site.baseurl }}/assets/resume.pdf" width="100%" height="800px" style="border: none;">
        This browser does not support PDFs. Please download the PDF to view it: 
        <a href="{{ site.baseurl }}/assets/resume.pdf">Download PDF</a>.
    </iframe>
</div>

<!-- ## Posts

{% for post in site.posts %}
- [{{ post.title }}]({{ post.url }})
{% endfor %} -->
